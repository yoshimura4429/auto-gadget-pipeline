import os, json, time, argparse
from pathlib import Path
from datetime import datetime
from dotenv import load_dotenv
import praw
import requests

# ========= è¨­å®š =========
WORK = Path("workspace"); WORK.mkdir(exist_ok=True)
INPUTS = Path("inputs"); INPUTS.mkdir(exist_ok=True)
RAW_JSON = WORK / "latest.json"
DRAFT_MD = INPUTS / "draft.md"

DEFAULT_SUBS = ["ipad", "apple", "ipados", "mac", "gadgets"]

# ========= ENV èª­ã¿è¾¼ã¿ =========
load_dotenv(dotenv_path=".env")
REDDIT_CLIENT_ID = os.getenv("REDDIT_CLIENT_ID")
REDDIT_CLIENT_SECRET = os.getenv("REDDIT_CLIENT_SECRET")
REDDIT_USER_AGENT = os.getenv("REDDIT_USER_AGENT", "my-reddit-app/0.1 by you")

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "")
OPENAI_PROJECT = os.getenv("OPENAI_PROJECT", "")
OPENAI_MODEL = os.getenv("OPENAI_MODEL", "gpt-4.1-mini")

def translate_keyword_if_needed(keyword: str, disable=False) -> str:
    """æ—¥æœ¬èªã£ã½ã‘ã‚Œã°è‹±è¨³ã€‚å¤±æ•—æ™‚ã‚„ç„¡åŠ¹åŒ–æ™‚ã¯ãã®ã¾ã¾è¿”ã™ã€‚"""
    if disable or not OPENAI_API_KEY:
        return keyword
    # ã²ã‚‰ãŒãªãƒ»ã‚«ã‚¿ã‚«ãƒŠãƒ»æ¼¢å­—ãŒå«ã¾ã‚Œã¦ã„ã‚Œã°ç¿»è¨³å€™è£œ
    if not any("\u3040" <= ch <= "\u30ff" or "\u4e00" <= ch <= "\u9fff" for ch in keyword):
        return keyword
    try:
        headers = {"Authorization": f"Bearer {OPENAI_API_KEY}", "Content-Type": "application/json"}
        if OPENAI_PROJECT:
            headers["OpenAI-Project"] = OPENAI_PROJECT
        payload = {
            "model": OPENAI_MODEL,
            "messages": [
                {"role": "system", "content": "You translate Japanese search keywords into concise English search terms (1-3 words). Output English only."},
                {"role": "user", "content": keyword}
            ],
            "temperature": 0.2
        }
        r = requests.post("https://api.openai.com/v1/chat/completions", headers=headers, json=payload, timeout=30)
        r.raise_for_status()
        text = r.json()["choices"][0]["message"]["content"].strip()
        # ã‚«ãƒ³ãƒã‚„æ”¹è¡Œã‚’æ¶ˆã—ã¦çŸ­ã
        return " ".join(text.replace(",", " ").split())[:60]
    except Exception:
        return keyword

def reddit_client():
    if not (REDDIT_CLIENT_ID and REDDIT_CLIENT_SECRET):
        raise RuntimeError("Reddit èªè¨¼æƒ…å ±ãŒä¸è¶³ã—ã¦ã„ã¾ã™ï¼ˆ.env ã® REDDIT_CLIENT_ID / REDDIT_CLIENT_SECRET / REDDIT_USER_AGENT ã‚’ç¢ºèªï¼‰")
    return praw.Reddit(
        client_id=REDDIT_CLIENT_ID,
        client_secret=REDDIT_CLIENT_SECRET,
        user_agent=REDDIT_USER_AGENT,
        ratelimit_seconds=5,
    )

def collect(keyword:str, subs:list, limit:int=12, max_comments:int=12):
    reddit = reddit_client()
    sub_union = "+".join(subs)
    results = {
        "keyword_input": keyword,
        "subs": subs,
        "collected_at": datetime.now().isoformat(),
        "posts": []
    }
    # relevance ã‚’å„ªå…ˆã€è¤‡æ•°ã‚µãƒ–ã‚’æ¨ªæ–­
    for submission in reddit.subreddit(sub_union).search(keyword, sort="relevance", limit=limit):
        post = {
            "subreddit": str(submission.subreddit),
            "title": submission.title,
            "url": f"https://www.reddit.com{submission.permalink}",
            "score": int(submission.score or 0),
            "comments": []
        }
        # ä¸Šä½ã‚³ãƒ¡ãƒ³ãƒˆã‚’å–å¾—ï¼ˆã‚¹ãƒ‘ãƒ /çŸ­æ–‡ã¯è»½ããƒ•ã‚£ãƒ«ã‚¿ï¼‰
        submission.comments.replace_more(limit=0)
        comments = sorted(submission.comments, key=lambda c: getattr(c, "score", 0), reverse=True)[:max_comments]
        for c in comments:
            body = getattr(c, "body", "") or ""
            if len(body.strip()) < 40: 
                continue
            post["comments"].append({
                "score": int(getattr(c, "score", 0) or 0),
                "text": body.strip()
            })
        if post["comments"]:
            results["posts"].append(post)
    return results

def save_json(path: Path, obj):
    path.write_text(json.dumps(obj, ensure_ascii=False, indent=2), encoding="utf-8")

def build_draft_md(data:dict, keyword:str, keyword_en:str):
    lines = []
    lines.append(f"# å©ãå°ï¼ˆ{keyword} / {keyword_en}ï¼‰")
    lines.append("")
    lines.append("â€» ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯ Reddit ã®ç”Ÿã®å£°ã‚’ç¨®ã«ã—ãŸâ€œä¸‹æ›¸ãâ€ã§ã™ã€‚å›ºæœ‰åè©ã®å‡ºå…¸ã¯æœ¬æ–‡ã§ã¼ã‹ã—ã¦æ‰±ã£ã¦ãã ã•ã„ï¼ˆä¾‹ï¼šã€Œãƒãƒƒãƒˆã®å£°ã§ã¯ã€ï¼‰ã€‚")
    lines.append("")
    # ç°¡æ˜“ãƒã‚¤ãƒ©ã‚¤ãƒˆæŠ½å‡ºï¼ˆè¶…ã–ã£ãã‚Šï¼‰
    pros, cons, use = [], [], []
    quotes = []
    for p in data.get("posts", []):
        for c in p.get("comments", []):
            t = c["text"]
            if any(w in t.lower() for w in ["light", "portable", "battery", "workflow", "seamless", "love", "perfect"]):
                pros.append(t[:220].replace("\n"," "))
            if any(w in t.lower() for w in ["heavy", "weight", "bug", "issue", "problem", "price"]):
                cons.append(t[:220].replace("\n"," "))
            if any(w in t.lower() for w in ["use", "reading", "note", "sketch", "edit", "work", "study"]):
                use.append(t[:220].replace("\n"," "))
            if len(quotes) < 8 and len(t) > 120:
                quotes.append(t.strip())
    lines += ["## ã–ã£ãã‚Šè¦ç‚¹", ""]
    lines += ["- å¼·ã¿: " + (", ".join(list(dict.fromkeys(pros))[:5]) if pros else "ï¼ˆã“ã‚Œã‹ã‚‰è¿½è¨˜ï¼‰")]
    lines += ["- å¼±ã¿: " + (", ".join(list(dict.fromkeys(cons))[:5]) if cons else "ï¼ˆã“ã‚Œã‹ã‚‰è¿½è¨˜ï¼‰")]
    lines += ["- ä½¿ã„é“: " + (", ".join(list(dict.fromkeys(use))[:5]) if use else "ï¼ˆã“ã‚Œã‹ã‚‰è¿½è¨˜ï¼‰"), ""]
    lines += ["## å¼•ç”¨ãƒ¡ãƒ¢ï¼ˆæŠœç²‹ãƒ»æ„è¨³OKï¼‰", ""]
    for q in quotes:
        lines.append(f"> {q}\n")
    lines += ["## å©ãå°ã‚¢ã‚¦ãƒˆãƒ©ã‚¤ãƒ³", ""]
    lines += [
        "### å°å…¥ãƒ¡ãƒ¢",
        "- ä½•ã«æ‚©ã‚“ã§ä½•ã‚’è©¦ã—ãŸã‹ã€‚æœ€åˆã®é•å’Œæ„Ÿã‚„ã¤ã¾ãšãã€‚",
        "",
        "### é­…åŠ›ï¼ˆæ‰€æœ‰æ„Ÿãƒ»é€£æºãƒ»æ‰‹è»½ã•ï¼‰",
        "- æ„Ÿæƒ…ãƒ™ãƒ¼ã‚¹ã®è‰¯ã• + å°ã•ãªæ°—ã¥ãã€‚",
        "",
        "### æ¯”è¼ƒã¨æºã‚‰ã",
        "- æ•°å­—ã‚„ä½¿ç”¨æ„Ÿï¼ˆé‡é‡/ä¾¡æ ¼/é›»æ± ï¼‰ã‚’å…¥ã‚Œã¤ã¤ã€å¿ƒãŒæºã‚Œã‚‹ç¬é–“ã€‚",
        "",
        "### ãƒ‡ãƒ¡ãƒªãƒƒãƒˆã¨å¯¾å‡¦",
        "- æ­£é¢ã‹ã‚‰èª²é¡Œã«è§¦ã‚Œã¦ã€ç¾å®Ÿçš„ãªè§£æ±ºæ¡ˆã€‚",
        "",
        "### æ´»ç”¨æ³•ï¼ˆãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ï¼‰",
        "- èª­æ›¸ / ä¼šè­°ãƒ¡ãƒ¢ / ã‚¯ãƒªã‚¨ã‚¤ãƒ†ã‚£ãƒ–ä¸‹æ›¸ã ãªã©1æ—¥ã®æµã‚Œã§ã€‚",
        ""
    ]
    return "\n".join(lines)

def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--keyword", required=True, help="æ—¥æœ¬èªã§ã‚‚OKã€‚å¿…è¦ã«å¿œã˜ã¦è‹±è¨³ã—ã¦æ¤œç´¢")
    ap.add_argument("--subs", default=",".join(DEFAULT_SUBS), help="ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Š subreddit")
    ap.add_argument("--limit", type=int, default=12)
    ap.add_argument("--no-translate", action="store_true", help="è‹±è¨³ã‚’è¡Œã‚ãªã„")
    args = ap.parse_args()

    subs = [s.strip() for s in args.subs.split(",") if s.strip()]
    keyword_en = translate_keyword_if_needed(args.keyword, disable=args.no_translate)

    print(f"ğŸ” keyword_ja='{args.keyword}' | keyword_en='{keyword_en}' | subs={subs}")
    data = collect(keyword_en, subs, limit=args.limit)
    save_json(RAW_JSON, data)
    print(f"ğŸ’¾ åŸãƒ‡ãƒ¼ã‚¿ä¿å­˜: {RAW_JSON}")

    draft = build_draft_md(data, args.keyword, keyword_en)
    DRAFT_MD.write_text(draft, encoding="utf-8")
    print(f"ğŸ“ å©ãå°ã‚’ä½œæˆ: {DRAFT_MD}")

if __name__ == "__main__":
    main()